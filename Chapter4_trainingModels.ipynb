{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Generate a linear-like distribution & fit\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=np.random.rand(100,1)\n",
    "y = 6+np.random.rand(100,1) + 2*x \n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Best estimates (computed) for intercept and slope are:\n",
      "[[6.5125171 ]\n",
      " [1.98692313]]\n"
     ]
    }
   ],
   "source": [
    "#Compute best estimates of the parameters, offset and slope\n",
    "#Here X_b has first column as a collection of 1s because x_0\n",
    "# is 1. Basically, Y = c + mx or Y = (c m).X_b\n",
    "\n",
    "X_b = np.c_[np.ones((100,1)), x]\n",
    "#print(X_b)\n",
    "print(\"\\n\")\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y)\n",
    "print(\"Best estimates (computed) for intercept and slope are:\")\n",
    "print(theta_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.5125171]), array([[1.98692313]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What we did above is performed by sklearn behind-the-scenes. \n",
    "# Here are the sklearn commands to find the best estimates\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(x,y)\n",
    "\n",
    "#print the best estimates for the fit coefficients\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm of initialized gradient =  1.4142135623730951\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[[6.4947279 ]\n",
      " [2.02316888]]\n"
     ]
    }
   ],
   "source": [
    "#Gradient descent\n",
    "\n",
    "from numpy import linalg as la\n",
    "\n",
    "eta = 0.5 #step size or learning rate\n",
    "m = 100 #number of instances or row entries\n",
    "\n",
    "theta = np.random.randn(2,1) #random initialization of \n",
    "                       #the two coefficients\n",
    "\n",
    "gradients = np.array([1,1])\n",
    "e = 0.005 #tolerance\n",
    "print(\"norm of initialized gradient = \",la.norm(gradients))\n",
    "while la.norm(gradients) > e:\n",
    "    gradients = 2/m * X_b.T.dot(X_b.dot(theta) - y)\n",
    "    #print(\"gradient = \", gradients)\n",
    "    theta = theta - eta*gradients\n",
    "    #print(theta[0], gradients[0])\n",
    "    plt.plot(theta[0], gradients[0], 'r.', ms=5)\n",
    "    \n",
    "plt.xlim([6,7]); plt.ylim([-0.1,0.1])\n",
    "plt.show()\n",
    "print(\"\\n\")\n",
    "print(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.52076018]\n",
      " [2.07669845]]\n"
     ]
    }
   ],
   "source": [
    "#Stochastic gradient descent\n",
    "\n",
    "#In stochastic gradient descent, the best estimates for the \n",
    "#coefficients are calculated per entry in the data, unlike \n",
    "# in batch gradient descent. \n",
    "#Therefore, it requires much lesser iterations with the\n",
    "#full dataset to determine the best estimates with the \n",
    "#desired tolerance. \n",
    "\n",
    "#Define # of iterations or rounds\n",
    "n_epochs = 50\n",
    "\n",
    "#number of instances in the data\n",
    "m = 50\n",
    "\n",
    "#Learning schedule parameters\n",
    "t0, t1 = 5, 50\n",
    "\n",
    "#Define learning rate, or step size, per iteration. We decrease\n",
    "#the step size as we progress, to converge to a minimum. \n",
    "\n",
    "def learning_rate(t):\n",
    "    return t0/(t+t1)\n",
    "\n",
    "#Random initialization of the coefficients of the linear fit\n",
    "\n",
    "theta = np.random.randn(2,1)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(m):\n",
    "        #choose a random entry between 1 to m\n",
    "        index = np.random.randint(m)\n",
    "        xi = X_b[index:index+1]\n",
    "        yi = y[index:index+1]\n",
    "        gradients = 2*xi.T.dot(xi.dot(theta) - yi)\n",
    "        eta = learning_rate(epoch*m+i)\n",
    "        theta = theta - eta*gradients\n",
    "        \n",
    "print(\"\",  theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.50122431] [1.99209489]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/priyaroy/machine_learning/env/lib/python3.5/site-packages/sklearn/linear_model/stochastic_gradient.py:130: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Stochastic gradient descent using Scikit-learn\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter=50, penalty=None, eta0=0.1) \n",
    "#here eta is the starting learning rate\n",
    "\n",
    "sgd_reg.fit(x, y.ravel())\n",
    "#np.ravel() returns a 1 D array. It is the same as reshape(-1)\n",
    "\n",
    "print(sgd_reg.intercept_, sgd_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
